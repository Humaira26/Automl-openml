{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict, deque\n",
    "import copy\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.linalg import LinAlgError\n",
    "import scipy.sparse\n",
    "import sklearn\n",
    "# TODO use balanced accuracy!\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from autosklearn.pipeline.implementations.OneHotEncoder import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Allow multiple dependencies for a metafeature\n",
    "# TODO Add HelperFunction as an object\n",
    "class HelperFunctions(object):\n",
    "    def __init__(self):\n",
    "        self.functions = OrderedDict()\n",
    "        self.values = OrderedDict()\n",
    "\n",
    "    def clear(self):\n",
    "        self.values = OrderedDict()\n",
    "        self.computation_time = OrderedDict()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.functions.__iter__()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.functions.__getitem__(item)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        return self.functions.__setitem__(key, value)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        return self.functions.__delitem__(key)\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return self.functions.__contains__(item)\n",
    "\n",
    "    def is_calculated(self, key):\n",
    "        \"\"\"Return if a helper function has already been executed.\n",
    "        Necessary as get_value() can return None if the helper function hasn't\n",
    "        been executed or if it returned None.\"\"\"\n",
    "        return key in self.values\n",
    "\n",
    "    def get_value(self, key):\n",
    "        return self.values.get(key).value\n",
    "\n",
    "    def set_value(self, key, item):\n",
    "        self.values[key] = item\n",
    "\n",
    "    def define(self, name):\n",
    "        \"\"\"Decorator for adding helper functions to a \"dictionary\".\n",
    "        This behaves like a function decorating a function,\n",
    "        not a class decorating a function\"\"\"\n",
    "        def wrapper(metafeature_class):\n",
    "            instance = metafeature_class()\n",
    "            self.__setitem__(name, instance)\n",
    "            return instance\n",
    "        return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetafeatureFunctions(object):\n",
    "    def __init__(self):\n",
    "        self.functions = OrderedDict()\n",
    "        self.dependencies = OrderedDict()\n",
    "        self.values = OrderedDict()\n",
    "\n",
    "    def clear(self):\n",
    "        self.values = OrderedDict()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.functions.__iter__()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.functions.__getitem__(item)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        return self.functions.__setitem__(key, value)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        return self.functions.__delitem__(key)\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return self.functions.__contains__(item)\n",
    "\n",
    "    def get_value(self, key):\n",
    "        return self.values[key].value\n",
    "\n",
    "    def set_value(self, key, item):\n",
    "        self.values[key] = item\n",
    "\n",
    "    def is_calculated(self, key):\n",
    "        \"\"\"Return if a helper function has already been executed.\n",
    "        Necessary as get_value() can return None if the helper function hasn't\n",
    "        been executed or if it returned None.\"\"\"\n",
    "        return key in self.values\n",
    "\n",
    "    def get_dependency(self, name):\n",
    "        \"\"\"Return the dependency of metafeature \"name\".\n",
    "        \"\"\"\n",
    "        return self.dependencies.get(name)\n",
    "\n",
    "    def define(self, name, dependency=None):\n",
    "        \"\"\"Decorator for adding metafeature functions to a \"dictionary\" of\n",
    "        metafeatures. This behaves like a function decorating a function,\n",
    "        not a class decorating a function\"\"\"\n",
    "        def wrapper(metafeature_class):\n",
    "            instance = metafeature_class()\n",
    "            self.__setitem__(name, instance)\n",
    "            self.dependencies[name] = dependency\n",
    "            return instance\n",
    "        return wrapper\n",
    "    \n",
    "metafeatures = MetafeatureFunctions()\n",
    "helper_functions = HelperFunctions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task(task_id):\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    X, y = task.get_X_and_y()\n",
    "    train_indices, test_indices = task.get_train_test_split_indices()\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    dataset = openml.datasets.get_dataset(task.dataset_id)\n",
    "    _, _, cat = dataset.get_data(return_categorical_indicator=True,\n",
    "target=task.target_name)\n",
    "    del _\n",
    "    del dataset\n",
    "    cat = ['categorical' if c else 'numerical' for c in cat]\n",
    "\n",
    "    unique = np.unique(y_train)\n",
    "    mapping = {unique_value: i for i, unique_value in enumerate(unique)}\n",
    "    y_train = np.array([mapping[value] for value in y_train])\n",
    "    y_test = np.array([mapping[value] for value in y_test])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, cat = load_task(236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13400, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical', 'numerical']\n"
     ]
    }
   ],
   "source": [
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfInstances\n",
      "LogNumberOfInstances\n",
      "NumberofClasses\n",
      "NumberOfFeatures\n",
      "LogNumberOfFeatures\n",
      "MissingValues\n",
      "NumberOfInstancesWithMissingValues\n",
      "PercentageOfInstancesWithMissingValues\n",
      "NumberOfFeaturesWithMissingValues\n",
      "PercentageOfFeaturesWithMissingValues\n",
      "NumberOfMissingValues\n",
      "PercentageOfMissingValues\n",
      "NumberOfNumericFeatures\n",
      "NumberOfCategoricalFeatures\n",
      "RatioNumericalToNominal\n",
      "DatasetRatio\n",
      "LogDatasetRatio\n",
      "InverseDatasetRatio\n",
      "LogInverseDatasetRatio\n"
     ]
    }
   ],
   "source": [
    "### Simple features\n",
    "computed_features={}\n",
    "def NumberOfInstances(X, y, categorical):\n",
    "    return float(X.shape[0])\n",
    "computed_features['NumberOfInstances']=NumberOfInstances(X_train,y_train,cat)\n",
    "print('NumberOfInstances')\n",
    "\n",
    "def LogNumberOfInstances(X, y, categorical):\n",
    "    return np.log(computed_features[\"NumberOfInstances\"])\n",
    "computed_features['LogNumberOfInstances']=LogNumberOfInstances(X_train,y_train,cat)\n",
    "print('LogNumberOfInstances')\n",
    "    \n",
    "#Calculate the number of classes.\n",
    "#Calls np.unique on the targets. If the dataset is a multilabel dataset,\n",
    "#does this for each label seperately and returns the mean.    \n",
    "def NumberofClasses(X, y, categorical):\n",
    "    if len(y.shape) == 2:\n",
    "        return np.mean([len(np.unique(y[:,i])) for i in range(y.shape[1])])\n",
    "    else:\n",
    "        return float(len(np.unique(y)))\n",
    "computed_features['NumberofClasses']=NumberofClasses(X_train,y_train,cat)\n",
    "print('NumberofClasses')\n",
    "\n",
    "\n",
    "def NumberOfFeatures(X, y, categorical):\n",
    "    return float(X.shape[1])\n",
    "computed_features['NumberOfFeatures'] = NumberOfFeatures(X_train,y_train,cat)\n",
    "print('NumberOfFeatures')\n",
    "\n",
    "\n",
    "def LogNumberOfFeatures(X,y,categorical):\n",
    "    return np.log(computed_features['NumberOfFeatures'] )\n",
    "computed_features['LogNumberOfFeatures'] = LogNumberOfFeatures(X_train,y_train,cat)\n",
    "print('LogNumberOfFeatures')\n",
    "\n",
    "def MissingValues(X, y, categorical):\n",
    "    missing = ~np.isfinite(X)\n",
    "    return missing\n",
    "computed_features['MissingValues'] = MissingValues(X_train,y_train,cat)\n",
    "print('MissingValues')\n",
    "\n",
    "def NumberOfInstancesWithMissingValues(X, y, categorical):\n",
    "    missing = computed_features[\"MissingValues\"]\n",
    "    num_missing = missing.sum(axis=1)\n",
    "    return float(np.sum([1 if num > 0 else 0 for num in num_missing]))\n",
    "computed_features['NumberOfInstancesWithMissingValues'] = NumberOfInstancesWithMissingValues(X_train,y_train,cat)\n",
    "print('NumberOfInstancesWithMissingValues')\n",
    "\n",
    "\n",
    "def PercentageOfInstancesWithMissingValues(X, y, categorical):\n",
    "    return float(computed_features[\"NumberOfInstancesWithMissingValues\"]) / float(computed_features[\"NumberOfInstances\"])\n",
    "computed_features['PercentageOfInstancesWithMissingValues'] = PercentageOfInstancesWithMissingValues(X_train,y_train,cat)\n",
    "print('PercentageOfInstancesWithMissingValues')\n",
    "\n",
    "\n",
    "\n",
    "def NumberOfFeaturesWithMissingValues(X, y, categorical):\n",
    "        missing = computed_features[\"MissingValues\"]\n",
    "        num_missing = missing.sum(axis=0)\n",
    "        return float(np.sum([1 if num > 0 else 0 for num in num_missing]))\n",
    "computed_features['NumberOfFeaturesWithMissingValues'] = NumberOfFeaturesWithMissingValues(X_train,y_train,cat)\n",
    "print('NumberOfFeaturesWithMissingValues')\n",
    "\n",
    "def PercentageOfFeaturesWithMissingValues(X, y, categorical):\n",
    "        return float(computed_features[\"NumberOfFeaturesWithMissingValues\"]) / float(computed_features[\"NumberOfFeatures\"])\n",
    "computed_features['PercentageOfFeaturesWithMissingValues'] = PercentageOfFeaturesWithMissingValues(X_train,y_train,cat)\n",
    "print('PercentageOfFeaturesWithMissingValues')\n",
    "\n",
    "\n",
    "def NumberOfMissingValues(X, y, categorical):\n",
    "        return float(computed_features[\"MissingValues\"].sum())\n",
    "computed_features['NumberOfMissingValues'] = NumberOfMissingValues(X_train,y_train,cat)\n",
    "print('NumberOfMissingValues')\n",
    "\n",
    "\n",
    "def PercentageOfMissingValues(X, y, categorical):\n",
    "        return float(computed_features[\"NumberOfMissingValues\"]) / float(X.shape[0]*X.shape[1])\n",
    "computed_features['PercentageOfMissingValues'] = PercentageOfMissingValues(X_train,y_train,cat)\n",
    "print('PercentageOfMissingValues')\n",
    "\n",
    "\n",
    "def NumberOfNumericFeatures(X, y, categorical):\n",
    "    numerical_features=0\n",
    "    for i in categorical:\n",
    "        if i=='numerical':\n",
    "            numerical_features+=1\n",
    "    return numerical_features\n",
    "computed_features['NumberOfNumericFeatures'] = NumberOfNumericFeatures(X_train,y_train,cat)\n",
    "print('NumberOfNumericFeatures')\n",
    "\n",
    "def NumberOfCategoricalFeatures(X, y, categorical):\n",
    "    categorical_features=0\n",
    "    for i in categorical:\n",
    "        if i=='categorical':\n",
    "            categorical_features+=1\n",
    "    return categorical_features\n",
    "computed_features['NumberOfCategoricalFeatures'] = NumberOfCategoricalFeatures(X_train,y_train,cat)\n",
    "print('NumberOfCategoricalFeatures')\n",
    "\n",
    "def RatioNumericalToNominal(X, y, categorical):\n",
    "        num_categorical = float(computed_features[\"NumberOfCategoricalFeatures\"])\n",
    "        num_numerical = float(computed_features[\"NumberOfNumericFeatures\"])\n",
    "        if num_categorical == 0.0:\n",
    "            return 0.\n",
    "        return num_numerical / num_categorical\n",
    "computed_features['RatioNumericalToNominal'] = RatioNumericalToNominal(X_train,y_train,cat)\n",
    "print('RatioNumericalToNominal')\n",
    "\n",
    "\n",
    "# Number of attributes divided by number of samples\n",
    "\n",
    "def DatasetRatio(X, y, categorical):\n",
    "        return float(computed_features[\"NumberOfFeatures\"]) / float(computed_features[\"NumberOfInstances\"])\n",
    "computed_features['DatasetRatio'] = DatasetRatio(X_train,y_train,cat)\n",
    "print('DatasetRatio')\n",
    "                     \n",
    "def LogDatasetRatio(X, y, categorical):\n",
    "        return np.log(computed_features[\"DatasetRatio\"])\n",
    "computed_features['LogDatasetRatio'] = LogDatasetRatio(X_train,y_train,cat)\n",
    "print('LogDatasetRatio')                 \n",
    "                     \n",
    "def InverseDatasetRatio(X, y, categorical):\n",
    "        return float(computed_features[\"NumberOfInstances\"]) / float(computed_features[\"NumberOfFeatures\"])\n",
    "computed_features['InverseDatasetRatio'] = InverseDatasetRatio(X_train,y_train,cat)\n",
    "print('InverseDatasetRatio')\n",
    "                     \n",
    "def LogInverseDatasetRatio(X, y, categorical):\n",
    "        return np.log(computed_features[\"InverseDatasetRatio\"])\n",
    "computed_features['LogInverseDatasetRatio'] = LogInverseDatasetRatio(X_train,y_train,cat)\n",
    "print('LogInverseDatasetRatio')\n",
    "                     \n",
    "def ClassOccurences(X, y, categorical):\n",
    "        if len(y.shape) == 2:\n",
    "            occurences = []\n",
    "            for i in range(y.shape[1]):\n",
    "                occurences.append(self._calculate(X, y[:, i], cat))\n",
    "            return occurences\n",
    "        else:\n",
    "            occurence_dict = defaultdict(float)\n",
    "            for value in y:\n",
    "                occurence_dict[value] += 1\n",
    "            return occurence_dict\n",
    "computed_features['ClassOccurences'] = ClassOccurences(X_train,y_train,cat)\n",
    "\n",
    "def ClassProbabilityMin(X, y, categorical):\n",
    "        occurences = computed_features[\"ClassOccurences\"]\n",
    "\n",
    "        min_value = np.iinfo(np.int64).max\n",
    "        if len(y.shape) == 2:\n",
    "            for i in range(y.shape[1]):\n",
    "                for num_occurences in occurences[i].values():\n",
    "                    if num_occurences < min_value:\n",
    "                        min_value = num_occurences\n",
    "        else:\n",
    "            for num_occurences in occurences.values():\n",
    "                if num_occurences < min_value:\n",
    "                    min_value = num_occurences\n",
    "        return float(min_value) / float(y.shape[0])\n",
    "                     \n",
    "computed_features['ClassProbabilityMin'] = ClassProbabilityMin(X_train,y_train,cat)\n",
    "\n",
    "# aka default accuracy\n",
    "\n",
    "def ClassProbabilityMax(X, y, categorical):\n",
    "        occurences = computed_features[\"ClassOccurences\"]\n",
    "        max_value = -1\n",
    "\n",
    "        if len(y.shape) == 2:\n",
    "            for i in range(y.shape[1]):\n",
    "                for num_occurences in occurences[i].values():\n",
    "                    if num_occurences > max_value:\n",
    "                        max_value = num_occurences\n",
    "        else:\n",
    "            for num_occurences in occurences.values():\n",
    "                if num_occurences > max_value:\n",
    "                    max_value = num_occurences\n",
    "        return float(max_value) / float(y.shape[0])\n",
    "                     \n",
    "computed_features['ClassProbabilityMax'] = ClassProbabilityMax(X_train,y_train,cat)\n",
    "\n",
    "def ClassProbabilityMean(X, y, categorical):\n",
    "        occurence_dict = computed_features[\"ClassOccurences\"]\n",
    "        if len(y.shape) == 2:\n",
    "            occurences = []\n",
    "            for i in range(y.shape[1]):\n",
    "                occurences.extend(\n",
    "                    [occurrence for occurrence in occurence_dict[\n",
    "                        i].values()])\n",
    "            occurences = np.array(occurences)\n",
    "        else:\n",
    "            occurences = np.array([occurrence for occurrence in occurence_dict.values()],\n",
    "                                  dtype=np.float64)\n",
    "        return (occurences / y.shape[0]).mean()\n",
    "computed_features['ClassProbabilityMean'] = ClassProbabilityMean(X_train,y_train,cat)\n",
    "\n",
    "def ClassProbabilitySTD(X, y, categorical):\n",
    "        occurence_dict = computed_features[\"ClassOccurences\"]\n",
    "\n",
    "        if len(y.shape) == 2:\n",
    "            stds = []\n",
    "            for i in range(y.shape[1]):\n",
    "                std = np.array(\n",
    "                    [occurrence for occurrence in occurence_dict[\n",
    "                                                      i].values()],\n",
    "                    dtype=np.float64)\n",
    "                std = (std / y.shape[0]).std()\n",
    "                stds.append(std)\n",
    "            return np.mean(stds)\n",
    "        else:\n",
    "            occurences = np.array([occurrence for occurrence in occurence_dict.values()],\n",
    "                                 dtype=np.float64)\n",
    "            return (occurences / y.shape[0]).std()\n",
    "computed_features['ClassProbabilitySTD'] = ClassProbabilitySTD(X_train,y_train,cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NumberOfInstances': 13400.0,\n",
       " 'LogNumberOfInstances': 9.503009985939002,\n",
       " 'NumberofClasses': 26.0,\n",
       " 'NumberOfFeatures': 16.0,\n",
       " 'LogNumberOfFeatures': 2.772588722239781,\n",
       " 'MissingValues': array([[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]),\n",
       " 'NumberOfInstancesWithMissingValues': 0.0,\n",
       " 'PercentageOfInstancesWithMissingValues': 0.0,\n",
       " 'NumberOfFeaturesWithMissingValues': 0.0,\n",
       " 'PercentageOfFeaturesWithMissingValues': 0.0,\n",
       " 'NumberOfMissingValues': 0.0,\n",
       " 'PercentageOfMissingValues': 0.0,\n",
       " 'NumberOfNumericFeatures': 16,\n",
       " 'NumberOfCategoricalFeatures': 0,\n",
       " 'RatioNumericalToNominal': 0.0,\n",
       " 'DatasetRatio': 0.0011940298507462687,\n",
       " 'LogDatasetRatio': -6.730421263699221,\n",
       " 'InverseDatasetRatio': 837.5,\n",
       " 'LogInverseDatasetRatio': 6.730421263699221,\n",
       " 'ClassOccurences': defaultdict(float,\n",
       "             {6: 519.0,\n",
       "              3: 532.0,\n",
       "              1: 494.0,\n",
       "              16: 534.0,\n",
       "              4: 520.0,\n",
       "              14: 525.0,\n",
       "              12: 509.0,\n",
       "              23: 530.0,\n",
       "              24: 548.0,\n",
       "              22: 505.0,\n",
       "              20: 535.0,\n",
       "              7: 482.0,\n",
       "              25: 525.0,\n",
       "              11: 504.0,\n",
       "              18: 499.0,\n",
       "              0: 552.0,\n",
       "              19: 515.0,\n",
       "              8: 516.0,\n",
       "              21: 520.0,\n",
       "              15: 539.0,\n",
       "              10: 492.0,\n",
       "              9: 493.0,\n",
       "              13: 537.0,\n",
       "              5: 509.0,\n",
       "              2: 463.0,\n",
       "              17: 503.0}),\n",
       " 'ClassProbabilityMin': 0.03455223880597015,\n",
       " 'ClassProbabilityMax': 0.04119402985074627,\n",
       " 'ClassProbabilityMean': 0.038461538461538464,\n",
       " 'ClassProbabilitySTD': 0.0015347192175998684}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
